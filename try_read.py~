import nltk


#import re

#from urllib import urlopen 

#from nltk.corpus import stopwords

import csv 

#url = "http://hbr.org/2013/04/now-is-our-time/ar/1" 


#proxies = {'http': 'http://f2010193:bp1708@10.1.9.23:8080'} 

#raw = urlopen(url, proxies=proxies).read()

#cleanraw = nltk.clean_html(raw)

#rtoken = nltk.word_tokenize(cleanraw)  #this consists of raw tokens

#print(rtoken)

#removing words already analyzed in heading and title
#use sub func used for punctuation


import codecs


f = codecs.open('/media/34227B6E227B3448/projectBooKmarks/rawtext/new_cont/title/title.csv').read()


text = f.read()

a = nltk.word_tokenize(text)

print(a)



