#extraction of the raw text, title tag, heading tag, urls, url names

from BeautifulSoup import BeautifulSoup

from nltk.tokenize import *

import nltk

import re

from urllib import urlopen

import csv 

from nltk.corpus import stopwords


url = "http://hbr.org/2013/04/now-is-our-time/ar/1" 
#keeping this along with other urls


proxies = {'http': 'http://f2010193:bp1708@10.1.9.23:8080'} 

raw = urlopen(url, proxies=proxies).read()

cleanraw = nltk.clean_html(raw)

#raw.txt contains the raw text
f = open('cleanraw_try.txt', 'w')   
f.write(cleanraw) 
f.close()



#tokenize cleanraw
tok_clean = nltk.word_tokenize(cleanraw)


#removing all the smartquotes

clean = []

for x in tok_clean:
    if "&" not in x:
        clean.append(x) 


#raw.txt contains the raw text
f = open('no_sq.txt', 'w')   
f.write("\t".join(clean)) 
f.close()



# Split words by all non-alpha characters
#words=re.compile(r'[^A-Z^a-z]+').split(cleanraw)

#t = type(words)

#print t


#raw.txt contains the raw text
#f = open('raw_try.txt', 'w')   
#f.write("\t".join(words)) 
#f.close()


